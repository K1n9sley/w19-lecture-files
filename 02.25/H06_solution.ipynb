{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6 notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the standard imports for CS 111. \n",
    "# This list may change as the quarter goes on.\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import struct\n",
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import numpy.linalg as npla\n",
    "import scipy\n",
    "import scipy.sparse.linalg as spla\n",
    "from scipy import sparse\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "%matplotlib tk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank1(E, return_vector = False, max_iters = 1000, tolerance = 1e-6):\n",
    "    \"\"\"compute page rank from dense adjacency matrix\n",
    "\n",
    "    Inputs:\n",
    "      E: adjacency matrix with links going from cols to rows.\n",
    "         E is a matrix of 0s and 1s, where E[i,j] = 1 means \n",
    "         that web page (vertex) j has a link to web page i.\n",
    "      return_vector = False: If True, return the eigenvector as well as the ranking.\n",
    "      max_iters = 1000: Maximum number of power iterations to do.\n",
    "      tolerance = 1e-6: Stop when the eigenvector norm changes by less than this.\n",
    "      \n",
    "    Outputs:\n",
    "      ranking: Permutation giving the ranking, most important first\n",
    "      vector (only if return_vector is True): Dominant eigenvector of PageRank matrix\n",
    "\n",
    "    This computes page rank by the following steps:\n",
    "    1. Add links from any dangling vertices to all vertices.\n",
    "    2. Scale the columns to sum to 1.\n",
    "    3. Add a constant matrix to represent jumping at random 15% of the time.\n",
    "    4. Find the dominant eigenvector with the power method.\n",
    "    5. Sort the eigenvector to get the rankings.\n",
    "\n",
    "    The homework problem due February 22 asks you to rewrite this code so\n",
    "    it takes input E as a scipy csr_sparse matrix, and then never creates \n",
    "    a full matrix or any large matrix other than E.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(E) is not np.ndarray:\n",
    "        print('Warning, converting input from type', type(E), 'to dense array.')\n",
    "        E = E.toarray()\n",
    "                \n",
    "    nnz = np.count_nonzero(E) # This call for sparse E may be different\n",
    "    outdegree = np.sum(E, 0)  # This call for sparse E may be different\n",
    "    nrows, n = E.shape\n",
    "\n",
    "    assert nrows == n, 'E must be square'\n",
    "    assert np.max(E) == 1 and np.sum(E) == nnz, 'E must contain only zeros and ones'\n",
    "    \n",
    "    #  1. Add links from any dangling vertices to all other vertices.\n",
    "    #     E + F will be the matrix with the added links.\n",
    "\n",
    "    F = np.zeros((n,n))\n",
    "    for j in range(n):\n",
    "        if outdegree[j] == 0:\n",
    "            F[:,j] = np.ones(n)\n",
    "            F[j,j] = 0\n",
    "    \n",
    "    #  2. Scale the columns to sum to 1.\n",
    "\n",
    "    A = (E + F) / np.sum(E + F, 0)\n",
    "    \n",
    "    #  3. Add a constant matrix to represent jumping at random 15% of the time.\n",
    "\n",
    "    S = np.ones((n,n)) / n\n",
    "    m = 0.15\n",
    "    M = (1 - m) * A + m * S\n",
    "    \n",
    "    #  4. Find the dominant eigenvector.\n",
    "    #  Start with a vector all of whose entries are equal.\n",
    "\n",
    "    e = np.ones(n)\n",
    "    v = e / npla.norm(e)\n",
    "\n",
    "    for iteration in range(max_iters):\n",
    "        oldv = v\n",
    "        \n",
    "        v = M @ v\n",
    "        eigval = npla.norm(v)\n",
    "        v = v / eigval\n",
    "        \n",
    "        if npla.norm(v - oldv) < tolerance:\n",
    "            break\n",
    "    \n",
    "    if npla.norm(v - oldv) < tolerance:\n",
    "        print('Dominant eigenvalue is %f after %d iterations.\\n' % (eigval, iteration+1))\n",
    "    else:\n",
    "        print('Did not converge to tolerance %e after %d iterations.\\n' % (tolerance, max_iters))\n",
    "\n",
    "    # Check that the eigenvector elements are all the same sign, and make them positive\n",
    "    assert np.all(v > 0) or np.all(v < 0), 'Error: eigenvector is not all > 0 or < 0'\n",
    "    vector = np.abs(v)\n",
    "        \n",
    "    #  5. Sort the eigenvector and reverse the permutation to get the rankings.\n",
    "    ranking = np.argsort(vector)[::-1]\n",
    "\n",
    "    if return_vector:\n",
    "        return ranking, vector\n",
    "    else:\n",
    "        return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank2(E, return_vector = False, max_iters = 1000, tolerance = 1e-6):\n",
    "    \"\"\"compute page rank from sparse adjacency matrix\n",
    "\n",
    "    Inputs:\n",
    "      E: adjacency matrix with links going from cols to rows.\n",
    "         E is a matrix of 0s and 1s, where E[i,j] = 1 means \n",
    "         that web page (vertex) j has a link to web page i.\n",
    "      return_vector = False: If True, return the eigenvector as well as the ranking.\n",
    "      max_iters = 1000: Maximum number of power iterations to do.\n",
    "      tolerance = 1e-6: Stop when the eigenvector norm changes by less than this.\n",
    "      \n",
    "    Outputs:\n",
    "      ranking: Permutation giving the ranking, most important first.\n",
    "      vector (only if return_vector is True): Dominant eigenvector of PageRank matrix.\n",
    "\n",
    "    This computes page rank by the following steps:\n",
    "    1. Add links from any dangling vertices to all vertices.\n",
    "    2. Scale the columns to sum to 1.\n",
    "    3. Add a constant matrix to represent jumping at random 15% of the time.\n",
    "    4. Find the dominant eigenvector with the power method.\n",
    "    5. Sort the eigenvector to get the rankings.\n",
    "    \n",
    "    This computes the same page rank as pagerank1, but it never creates\n",
    "    a new matrix as large as E.\n",
    "    Instead, it computes the matrix-vector product M @ v in the power method\n",
    "    in several steps corresponding to the steps in converting E to M.\n",
    "    \"\"\"\n",
    "\n",
    "    # sparse and dense matrices do some things differently, sigh...\n",
    "    if type(E) is not scipy.sparse.csr.csr_matrix:\n",
    "        print('Warning, converting input from type', type(E), 'to sparse csr_matrix.')\n",
    "        E = sparse.csr_matrix(E)\n",
    "\n",
    "    nnz = E.count_nonzero()\n",
    "    outdegree = np.array(E.sum(axis = 0))[0]\n",
    "    nrows, n = E.shape\n",
    "\n",
    "    assert nrows == n, 'E must be square'\n",
    "    assert np.max(E) == 1 and np.sum(E) == nnz, 'E must contain only zeros and ones'\n",
    "    \n",
    "    #  1. Add links from any dangling vertices to all other vertices.\n",
    "    #     We don't add any actual links or compute the matrix F with full columns, \n",
    "    #     but just compute the vector \"d\" that picks out the nonzero cols of F.\n",
    "    #     Then, formally, F = (J - I) @ D,\n",
    "    #     where J is the all-ones matrix, I is the identity, and D is diag(d),\n",
    "    #     but we don't ever form I or J or D or F explicitly.\n",
    "    #\n",
    "    #  2. Scale the columns of E + F to sum to 1.\n",
    "    #     Again we don't compute a whole matrix, just a vector \"t\"\n",
    "    #     for which the columns of (E + F) @ diag(t) sum to 1\n",
    "    #     so, formally, A = (E + F) @ T,\n",
    "    #     where F is as above and T = diag(t).\n",
    "    #     Each element of t is one over a column sum of E or of F.\n",
    "    #\n",
    "    #  We do both steps (1) and (2) in the same loop below.\n",
    "   \n",
    "    t = np.zeros(n)\n",
    "    d = np.zeros(n) \n",
    "    for j in range(n):\n",
    "        if outdegree[j] == 0:\n",
    "            t[j] = 1 / (n-1)\n",
    "            d[j] = 1\n",
    "        else:\n",
    "            t[j] = 1 / outdegree[j]\n",
    "            d[j] = 0\n",
    "    \n",
    "    \n",
    "    #  3. Add a constant matrix to represent jumping at random 15% of the time.\n",
    "    #     Again we don't do this explicitly, just get the ingredients for:\n",
    "    #         M = (1-m) * A + m * J / n\n",
    "\n",
    "    m = 0.15\n",
    "    \n",
    "    #  4. Find the dominant eigenvector.\n",
    "    #     Here we use the power method, just as in pagerank1, but we\n",
    "    #     implement the matrix-vector multiplication M @ v in several steps.\n",
    "    \n",
    "    #  Start with v as a vector all of whose entries are 1/n.\n",
    "\n",
    "    e = np.ones(n)\n",
    "    v = e / npla.norm(e)\n",
    "\n",
    "    for iteration in range(max_iters):\n",
    "        oldv = v\n",
    "             \n",
    "        # Now  M @ v = (1-m)*(E + F) @ T @ v  +  m/n * J @ v.\n",
    "        #\n",
    "        # If we let w = T @ v = v * t, and note that J @ v = np.sum(v)*e, we get\n",
    "        #   M @ v = (1-m) * E @ w + (1-m) * F @ w + m/n * np.sum(v)*e, \n",
    "        # and since F @ w = J @ D @ w - I @ D @ w = np.sum(w*d) * e - w*d, we finally have\n",
    "        #   M @ v = (1-m)*(E@w) + (1-m)*np.sum(w*d)*e - (1-m)*w*d + (m/n)*np.sum(v)*e,\n",
    "        # which requires no matrices except E, multiplying the vector w.\n",
    "        \n",
    "        w  = v * t                   # * is elementwise multiply; v, t, w are vectors \n",
    "        wd = w * d                   # elementwise multiply again; w, d, and wd are vectors\n",
    "        v1 = (1-m) * (E @ w)         # the only matrix is the original E, times vector w\n",
    "        v2 = (1-m) * np.sum(wd) * e  # scalar times vector e\n",
    "        v3 = (1-m) * wd              # scalar times vector w\n",
    "        v4 = (m/n) * np.sum(v) * e   # scalar times vector e\n",
    "        v = v1 + v2 - v3 + v4        # adding and subtracting vectors                 \n",
    "                    \n",
    "        eigval = npla.norm(v)\n",
    "        v = v / eigval\n",
    "        \n",
    "        if npla.norm(v - oldv) < tolerance:\n",
    "            break\n",
    "    \n",
    "    if npla.norm(v - oldv) < tolerance:\n",
    "        print('Dominant eigenvalue is %f after %d iterations.\\n' % (eigval, iteration+1))\n",
    "    else:\n",
    "        print('Did not converge to tolerance %e after %d iterations.\\n' % (tolerance, max_iters))\n",
    "\n",
    "    # Check that the eigenvector elements are all the same sign, and make them positive\n",
    "    assert np.all(v > 0) or np.all(v < 0), 'Error: eigenvector is not all > 0 or < 0'\n",
    "    vector = np.abs(v)\n",
    "        \n",
    "    #  5. Sort the eigenvector and reverse the permutation to get the rankings.\n",
    "    ranking = np.argsort(vector)[::-1]\n",
    "\n",
    "    if return_vector:\n",
    "        return ranking, vector\n",
    "    else:\n",
    "        return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gilbert/Documents/CS_111_2019_Winter/Data\n"
     ]
    }
   ],
   "source": [
    "%cd ../Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant eigenvalue is 1.000000 after 19 iterations.\n",
      "\n",
      "r = [0 2 3 1]\n",
      "v = [0.69648305 0.26828106 0.54477799 0.38230039]\n"
     ]
    }
   ],
   "source": [
    "E = np.load('PageRankEG1.npy')\n",
    "r, v = pagerank1(E, return_vector = True)\n",
    "print('r =', r)\n",
    "print('v =', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, converting input from type <class 'numpy.ndarray'> to sparse csr_matrix.\n",
      "Dominant eigenvalue is 1.000000 after 19 iterations.\n",
      "\n",
      "r = [0 2 3 1]\n",
      "v = [0.69648305 0.26828106 0.54477799 0.38230039]\n"
     ]
    }
   ],
   "source": [
    "E = np.load('PageRankEG1.npy')\n",
    "r, v = pagerank2(E, return_vector = True)\n",
    "print('r =', r)\n",
    "print('v =', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant eigenvalue is 1.000000 after 56 iterations.\n",
      "\n",
      "r[:10] = [  0   9  41 129  17  14   8  16  45  12]\n",
      "\n",
      "rank 0 is page   0: http://www.harvard.edu\n",
      "rank 1 is page   9: http://www.hbs.edu\n",
      "rank 2 is page  41: http://search.harvard.edu:8765/custom/query.html\n",
      "rank 3 is page 129: http://www.med.harvard.edu\n",
      "rank 4 is page  17: http://www.gse.harvard.edu\n",
      "rank 5 is page  14: http://www.hms.harvard.edu\n",
      "rank 6 is page   8: http://www.ksg.harvard.edu\n",
      "rank 7 is page  16: http://www.hsph.harvard.edu\n",
      "rank 8 is page  45: http://www.gocrimson.com\n",
      "rank 9 is page  12: http://www.hsdm.med.harvard.edu\n"
     ]
    }
   ],
   "source": [
    "E = np.load('PageRankEG3.npy')\n",
    "sitename = open('PageRankEG3.nodelabels').read().splitlines()\n",
    "r, v = pagerank1(E, return_vector = True)\n",
    "print('r[:10] =', r[:10])\n",
    "print()\n",
    "for i in range(10):\n",
    "    print('rank %d is page %3d: %s' % (i, r[i], sitename[r[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading matrix from webGoogle.npz\n",
      "\n",
      "CPU times: user 356 ms, sys: 92.8 ms, total: 448 ms\n",
      "Wall time: 454 ms\n",
      "\n",
      "Done loading 916428-by-916428 matrix.\n",
      "\n",
      "Starting pagerank2...\n",
      "Dominant eigenvalue is 1.000000 after 71 iterations.\n",
      "\n",
      "CPU times: user 9.06 s, sys: 409 ms, total: 9.47 s\n",
      "Wall time: 5.19 s\n",
      "\n",
      "Done with pagerank2:\n",
      "r[:10] = [ 34312  96071 412410  50061 506742 295123 553985 357570 285814 899572]\n",
      "\n",
      "Starting spla.eigs...\n",
      "CPU times: user 17 s, sys: 370 ms, total: 17.4 s\n",
      "Wall time: 9.07 s\n",
      "\n",
      "Done with spla.eigs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matname = 'webGoogle'\n",
    "\n",
    "print('Loading matrix from %s.npz\\n' % matname)\n",
    "%time E = sparse.load_npz(matname + '.npz')\n",
    "print('\\nDone loading %d-by-%d matrix.' % E.shape)\n",
    "n = E.shape[0]\n",
    " \n",
    "print('\\nStarting pagerank2...')\n",
    "%time r = pagerank2(E)\n",
    "print('\\nDone with pagerank2:')\n",
    "print('r[:10] =', r[:10])\n",
    "print('\\nStarting spla.eigs...')\n",
    "%time d, V = spla.eigs(E, k = min(6, E.shape[0]-2))\n",
    "print('\\nDone with spla.eigs.\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading matrix from PageRankEG3.npy\n",
      "\n",
      "CPU times: user 2.25 ms, sys: 10.3 ms, total: 12.6 ms\n",
      "Wall time: 11.2 ms\n",
      "\n",
      "Done loading 500-by-500 matrix.\n",
      "\n",
      "Starting pagerank1...\n",
      "Dominant eigenvalue is 1.000000 after 56 iterations.\n",
      "\n",
      "CPU times: user 24.2 ms, sys: 8.57 ms, total: 32.7 ms\n",
      "Wall time: 21.2 ms\n",
      "\n",
      "Done with pagerank1:\n",
      "r[:10] = [  0   9  41 129  17  14   8  16  45  12]\n",
      "\n",
      "Starting pagerank2...\n",
      "Warning, converting input from type <class 'numpy.ndarray'> to sparse csr_matrix.\n",
      "Dominant eigenvalue is 1.000000 after 56 iterations.\n",
      "\n",
      "CPU times: user 20.7 ms, sys: 847 µs, total: 21.5 ms\n",
      "Wall time: 13.2 ms\n",
      "\n",
      "Done with pagerank2:\n",
      "r[:10] = [  0   9  41 129  17  14   8  16  45  12]\n",
      "\n",
      "Starting linalg.eig...\n",
      "CPU times: user 170 ms, sys: 19.6 ms, total: 189 ms\n",
      "Wall time: 107 ms\n",
      "\n",
      "Done with linalg.eig.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matname = 'PageRankEG3'\n",
    "\n",
    "print('Loading matrix from %s.npy\\n' % matname)\n",
    "%time E = np.load(matname + '.npy')\n",
    "print('\\nDone loading %d-by-%d matrix.' % E.shape)\n",
    "print('\\nStarting pagerank1...')\n",
    "%time r = pagerank1(E)\n",
    "print('\\nDone with pagerank1:')\n",
    "print('r[:10] =', r[:10]) \n",
    "print('\\nStarting pagerank2...')\n",
    "%time r = pagerank2(E)\n",
    "print('\\nDone with pagerank2:')\n",
    "print('r[:10] =', r[:10])\n",
    "print('\\nStarting linalg.eig...')\n",
    "%time d, V = linalg.eig(E)\n",
    "print('\\nDone with linalg.eig.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
